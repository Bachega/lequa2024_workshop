{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq8fYR6NY_7_"
      },
      "source": [
        "# init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmUgYPsj0Tw-",
        "outputId": "a2bb0820-5744-477f-bfe7-24e61b7dce92"
      },
      "outputs": [],
      "source": [
        "from quantifiers.CC import classify_count\n",
        "from quantifiers.ACC import ACC\n",
        "from quantifiers.dys_method import dys_method\n",
        "from quantifiers.MS import MS_method\n",
        "\n",
        "from utils.getTrainingScores import getTrainingScores\n",
        "from utils.getTPRFPR import getTPRFPR\n",
        "from utils.applyquantifiers import apply_quantifier\n",
        "from utils.fitQuantifierSchumacherGithub import fitQuantifierSchumacherGithub\n",
        "\n",
        "import pdb\n",
        "import quapy as qp\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from scipy.io.arff import loadarff\n",
        "from pprint import pprint\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "meta_table_path = './metafeatures/meta-table.csv'\n",
        "path = \"./datasets/\"\n",
        "files = os.listdir(path)\n",
        "\n",
        "\n",
        "# counters = [\"CC\",\"ACC\",\"SMM\",\"HDy\",\"DyS\",\"SORD\",\"MS\",\"MS2\",\"MAX\",\"X\",\"T50\"]\n",
        "counters = [\"CC\",\"ACC\",\"SMM\",\"HDy\",\"DyS\",\"SORD\",\"MS\",\"MS2\",\"MAX\",\"X\",\"T50\",\"PCC\",\"PACC\",\"GAC\",\"GPAC\",\"FM\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHUI9P42ZC5o"
      },
      "source": [
        "# preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdhBBmoIN0ew"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "dataframe = None\n",
        "X = None\n",
        "y = None\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "for f in files:\n",
        "  df = pd.read_csv(path + f)\n",
        "  df = df.dropna()\n",
        "\n",
        "  y = df.pop(df.columns[-1])\n",
        "  X = df\n",
        "\n",
        "  y_list.append(y.to_numpy())\n",
        "  X_list.append(X.to_numpy())\n",
        "\n",
        "  i += 1\n",
        "i = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVSD81CqPdjF"
      },
      "outputs": [],
      "source": [
        "meta_table = pd.read_csv(meta_table_path)\n",
        "meta_table_dict = {}\n",
        "\n",
        "for counter in counters:\n",
        "    meta_table_dict[counter] = meta_table.copy(deep = True)\n",
        "\n",
        "meta_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMQQS-h31g3c"
      },
      "source": [
        "# meta-features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5laWnKwkJh_X"
      },
      "outputs": [],
      "source": [
        "def run_experiment(X, y, dataset_name):\n",
        "  #......................input/output path directories....................\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "  rf_clf = None\n",
        "  rf_clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "  # try:\n",
        "  #   rf_clf = joblib.load('./models/' + dataset_name + '.joblib')\n",
        "  #   rf_clf.n_jobs = -1\n",
        "  # except:\n",
        "  #   rf_clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "\n",
        "  scores = getTrainingScores(X_train, y_train, 10, rf_clf)[0] # None\n",
        "  tprfpr = getTPRFPR(scores)\n",
        "  rf_clf.fit(X_train, y_train) \n",
        "\n",
        "  niterations = 10 # how many replicates it will take\n",
        "  batch_sizes = list([50]) # list(range(10, min(91, max_allowed + 1), 10))# + list(range(100, min(501, max_allowed + 1), 100)) # test set sizes\n",
        "  alpha_values = [round(x, 2) for x in np.linspace(0,1,20)]   # class proportion\n",
        "\n",
        "  pos_scores = scores[scores[\"class\"]==1][\"scores\"]\n",
        "  neg_scores = scores[scores[\"class\"]==0][\"scores\"]\n",
        "  \n",
        "  X_test = pd.DataFrame(X_test)\n",
        "  y_test = pd.DataFrame(y_test, columns=[str(len(X_test.columns))])\n",
        "  df_test = pd.concat([X_test, y_test], axis=1)\n",
        "  \n",
        "  # WAS ZERO (0) BEFORE\n",
        "  df_test_pos = df_test.loc[df_test[df_test.columns[-1]] == 1] # seperating positive test examples\n",
        "  df_test_neg = df_test.loc[df_test[df_test.columns[-1]] == 0] # seperating negative test examples\n",
        "  \n",
        "  # pdb.set_trace()\n",
        "\n",
        "  table=pd.DataFrame(columns=['quantifier', 'abs-error'])\n",
        "  for sample_size in batch_sizes:   # [10,100,500], batch_sizes, Varying test set sizes\n",
        "\n",
        "    for alpha in alpha_values: # Varying positive class distribution\n",
        "      # abs_error_cc = []\n",
        "      # abs_error_dys = []\n",
        "\n",
        "      error = []\n",
        "\n",
        "      for iter in range(niterations):\n",
        "        pos_size = int(round(sample_size * alpha, 2))\n",
        "        neg_size = sample_size - pos_size\n",
        "\n",
        "        #\n",
        "        # AVISAR O PROF ANDRE QUE SÃ“ FUNCIONOU COM REPLACE = TRUE\n",
        "        #\n",
        "        # df_test_neg\n",
        "        # sample_test_pos = df_test_pos.sample( int(pos_size), replace = False)\n",
        "        # sample_test_neg = df_test_neg.sample( int(neg_size), replace = False)\n",
        "        sample_test_pos = df_test_pos.sample( int(pos_size), replace = True)\n",
        "        sample_test_neg = df_test_neg.sample( int(neg_size), replace = True)\n",
        "\n",
        "        sample_test = pd.concat([sample_test_pos, sample_test_neg])\n",
        "\n",
        "        test_label = sample_test[sample_test.columns[-1]] # sample_test[\"class\"]\n",
        "\n",
        "        test_sample = sample_test.drop([sample_test.columns[-1]], axis=1) # sample_test.drop([\"class\"], axis=1)  #dropping class label columns\n",
        "        te_scores = rf_clf.predict_proba(test_sample)[:,1]  #estimating test sample scores\n",
        "\n",
        "        n_pos_sample_test = list(test_label).count(1) #Counting num of actual positives in test sample\n",
        "        calcultd_pos_prop = round(n_pos_sample_test/len(sample_test), 2) #actual pos class prevalence in generated sample\n",
        "\n",
        "        # print(counters)\n",
        "        for quantifier in counters:\n",
        "          #..............Test Sample QUAPY exp...........................\n",
        "          te_quapy = None\n",
        "          external_qnt = None\n",
        "          #if quantifier in ['EM', 'PWK']:\n",
        "          #  print('ok')\n",
        "          #  external_qnt = fitQuantifierSchumacherGithub(quantifier, X_train, y_train)                  \n",
        "          #  te_quapy = qp.data.LabelledCollection(sample_test.drop([\"class\",\"Binary_label\"], axis=1), test_label)\n",
        "          \n",
        "          #.............Calling of Methods..................................................\n",
        "          pred_pos_prop = apply_quantifier(qntMethod=quantifier,\n",
        "                                           clf=None,\n",
        "                                           scores=scores,\n",
        "                                           p_score=pos_scores,\n",
        "                                           n_score=neg_scores,\n",
        "                                           train_labels=None,\n",
        "                                           test_score=te_scores,\n",
        "                                           TprFpr=tprfpr,\n",
        "                                           thr=0.5,\n",
        "                                           measure='hellinger',\n",
        "                                           test_data=test_sample,\n",
        "                                           test_quapy=te_quapy,\n",
        "                                           external_qnt=external_qnt) #y_test=test_label\n",
        "          \n",
        "          pred_pos_prop = np.round(pred_pos_prop,2)  #predicted class proportion\n",
        "          \n",
        "          #..............................RESULTS Evaluation.....................................\n",
        "          abs_error = round(abs(calcultd_pos_prop - pred_pos_prop), 2) # absolute error\n",
        "\n",
        "          table.loc[len(table)] = [quantifier,abs_error]\n",
        "          # error = round(calcultd_pos_prop - pred_pos_prop, 2)     # simple error Biasness\n",
        "          \n",
        "  return table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2PwBTyQNRbn",
        "outputId": "08d1f61b-efcd-43dc-eede-44ff7e6d0c28"
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(random_state=42)\n",
        "skip_count = 0\n",
        "table = None\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "result = {}\n",
        "for counter in counters:\n",
        "    result[counter] = []\n",
        "\n",
        "file = open('log.txt', 'w')\n",
        "file.close()\n",
        "\n",
        "for i in range(0, len(X_list)):\n",
        "  try:\n",
        "    clf = RandomForestClassifier()\n",
        "\n",
        "    table = run_experiment(X_list[i], y_list[i], str(files[i].split('.csv')[0]))\n",
        "    table = table.groupby('quantifier')['abs-error'].aggregate('mean')\n",
        "\n",
        "    for key in counters:\n",
        "      result[key].append(table[key])\n",
        " \n",
        "    print('Finished ' + str(i))\n",
        "  except Exception as e:\n",
        "    print('Skipping ' + str(i) + '...\\t\\t\\t' + str(e))\n",
        "    for key in meta_table_dict:\n",
        "      meta_table_dict[key].drop(i, inplace = True)\n",
        "    skip_count += 1\n",
        "\n",
        "    file = open('log.txt', 'a')\n",
        "    file.write('Skipping ' + str(i) + '...\\t\\t\\t' + str(e) + '\\n')\n",
        "    file.close()\n",
        "\n",
        "  # # TEST\n",
        "  # if i == 20:\n",
        "  #   for key in meta_table_dict:\n",
        "  #     meta_table_dict[key].reset_index(drop=True, inplace=True)\n",
        "  #     meta_table_dict[key].drop(meta_table_dict[key].index[((i+1)-skip_count):], inplace=True)\n",
        "  #   break\n",
        "\n",
        "for key in meta_table_dict:\n",
        "  meta_table_dict[key]['abs-error'] = result[key]\n",
        "\n",
        "print('\\n\\nSkipped ' + str(skip_count) + ' dataset(s)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# meta_table_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "finSavePath = './metafeatures/meta-table'\n",
        "for c in counters:\n",
        "    meta_table_dict[c].to_csv(str(finSavePath + '-' + c + '.csv'), index = False)\n",
        "# test = pd.read_csv('./metafeatures/meta-table-DyS.csv')\n",
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test = pd.read_csv('./metafeatures/meta-table-MS2.csv')\n",
        "# test = test.pop(test.columns[-1])\n",
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# i = 0\n",
        "# for t in test:\n",
        "#     if np.isnan(t):\n",
        "#         print(i)\n",
        "#     i += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
